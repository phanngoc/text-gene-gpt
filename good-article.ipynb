{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Giải thích khá detail và visual nhiều:\n",
    "https://peterbloem.nl/blog/transformers\n",
    "https://minimaxir.com/2019/09/howto-gpt2/\n",
    "\n",
    "\n",
    "- Implementing BERT for Question and Answer\n",
    "https://niteshkumardew11.medium.com/implementing-bert-for-question-and-answer-67ccd0e8aae5\n",
    "- Thực hành Attention Layer\n",
    "https://phamdinhkhanh.github.io/2019/06/18/AttentionLayer.html#32-multi-head-attention\n",
    "- BERT Word Embeddings Tutorial\n",
    "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#23-segment-id\n",
    "\n",
    "\n",
    "- fine-tuning-the-gpt-2-large-language-model-unlocking-its\n",
    "https://212digital.medium.com/fine-tuning-the-gpt-2-large-language-model-unlocking-its-full-potential-66e3a082ab9c\n",
    "\n",
    "\n",
    "\n",
    "- Blog fine tuning dùng gpt2_simple utility.\n",
    "https://colab.research.google.com/drive/1CP-hLllqq4lpi0jFxGg_T51zj0tlu0SY?usp=sharing\n",
    "https://rowlando13.medium.com/everything-gpt-2-5-fine-tuning-885aec508c4\n",
    "https://github.com/minimaxir/gpt-2-simple\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
