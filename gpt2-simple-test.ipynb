{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ulity\n",
    "https://colab.research.google.com/drive/1CP-hLllqq4lpi0jFxGg_T51zj0tlu0SY?usp=sharing#scrollTo=4drWBjGtZwij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/33862420/ipython-notebook-how-to-reload-all-modules-in-a-specific-python-file\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tham khảo tài liệu notebook cho việc hiểu tham số:\n",
    "https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#scrollTo=aeXshJM-Cuaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 | 362.34] loss=0.01 avg=0.05\n",
      "[15 | 389.34] loss=0.01 avg=0.05\n",
      "[16 | 415.35] loss=0.01 avg=0.04\n",
      "[17 | 441.88] loss=0.01 avg=0.04\n",
      "[18 | 467.74] loss=0.01 avg=0.04\n",
      "[19 | 494.44] loss=0.01 avg=0.04\n",
      "[20 | 521.28] loss=0.01 avg=0.04\n",
      "Saving checkpoint/run1/model-20\n",
      "Finetuning Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "from gpt_2_me.gpt_2_simple.gpt_2 import *\n",
    "import gpt_2_me.gpt_2_simple.gpt_2 as gpt2\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "model_name = \"124M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n",
    "\n",
    "#setting parameters\n",
    "#the path to folder or files to train on\n",
    "dataset = \"../data/crawl_data_202303041834.csv\"\n",
    "\n",
    "#how many steps it will perform\n",
    "steps=20\n",
    "#determines whether to start from the base or a later checkpoint, more to follow about this\n",
    "restore_from = \"lastest\" \n",
    "#Set to `True` if you want to continue finetuning an existing model \n",
    "#(w/ `restore_from='latest'`) without creating duplicate copies. \n",
    "overwrite = True\n",
    "#how often to print results\n",
    "print_every=1\n",
    "#how often to provide with generated samples\n",
    "sample_every=100000\n",
    "#when providing sample, how many tokens to generate\n",
    "sample_length=100\n",
    "#how often to save a check point\n",
    "save_every=20\n",
    "\n",
    "#starting tensor flow session\n",
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "#finetuning\n",
    "gpt2.finetune(sess,\n",
    "                dataset=dataset,\n",
    "                model_name=model_name,\n",
    "                steps=steps,\n",
    "                restore_from='fresh',\n",
    "                run_name='run1',\n",
    "                overwrite=overwrite,\n",
    "                print_every=print_every,\n",
    "                sample_every=sample_every,\n",
    "                save_every=save_every, \n",
    "                sample_length=sample_length\n",
    "            )\n",
    "print(\"Finetuning Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path checkpoint/run1\n",
      "|<|startoftext|>147<|endoftext|>\n",
      "<|startoftext|>148<|endoftext|>\n",
      "<|startoftext|>149<|endoftext|>\n",
      "<|startoftext|>150<|endoftext|>\n",
      "<|startoftext|>151<|endoftext|>\n",
      "<|startoftext|>152<|endoftext|>\n",
      "<|startoftext|>153<|endoftext|>\n",
      "<|startoftext|>154<|endoftext|>\n",
      "<|startoftext|>155<|endoftext|>\n",
      "<|startoftext|>156<|endoftext|>\n",
      "<|startoftext|>157<|endoftext|>\n",
      "<|startoftext|>158<|endoftext|>\n",
      "<|startoftext|>159<|endoftext|>\n",
      "<|startoftext|>160<|endoftext|>\n",
      "<|startoftext|>161<|endoftext|>\n",
      "<|startoftext|>162<|endoftext|>\n",
      "<|startoftext|>163<|endoftext|>\n",
      "<|startoftext|>164<|endoftext|>\n",
      "<|startoftext|>165<|endoftext|>\n",
      "<|startoftext|>166<|endoftext|>\n",
      "<|startoftext|>167<|endoftext|>\n",
      "<|startoftext|>168<|endoftext|>\n",
      "<|startoftext|>169<|endoftext|>\n",
      "<|startoftext|>170<|endoftext|>\n",
      "<|startoftext|>171<|endoftext|>\n",
      "<|startoftext|>172<|endoftext|>\n",
      "<|startoftext|>173<|endoftext|>\n",
      "<|startoftext|>174<|endoftext|>\n",
      "<|startoftext|>175<|endoftext|>\n",
      "<|startoftext|>176<|endoftext|>\n",
      "<|startoftext|>177<|endoftext|>\n",
      "<|startoftext|>178<|endoftext|>\n",
      "<|startoftext|>179<|endoftext|>\n",
      "<|startoftext|>180<|endoftext|>\n",
      "<|startoftext|>181<|endoftext|>\n",
      "<|startoftext|>182<|endoftext|>\n",
      "<|startoftext|>183<|endoftext|>\n",
      "<|startoftext|>184<|endoftext|>\n",
      "<|startoftext|>185<|endoftext|>\n",
      "<|startoftext|>186<|endoftext|>\n",
      "<|startoftext|>187<|endoftext|>\n",
      "<|startoftext|>188<|endoftext|>\n",
      "<|startoftext|>189<|endoftext|>\n",
      "<|startoftext|>190<|endoftext|>\n",
      "<|startoftext|>191<|endoftext|>\n",
      "<|startoftext|>192<|endoftext|>\n",
      "<|startoftext|>193<|endoftext|>\n",
      "<|startoftext|>194<|endoftext|>\n",
      "<|startoftext|>195<|endoftext|>\n",
      "<|startoftext|>196<|endoftext|>\n",
      "<|startoftext|>197<|endoftext|>\n",
      "<|startoftext|>198<|endoftext|>\n",
      "<|startoftext|>199<|endoftext|>\n",
      "<|startoftext|>200<|endoftext|>\n",
      "<|startoftext|>201<|endoftext|>\n",
      "<|startoftext|>202<|endoftext|>\n",
      "<|startoftext|>203<|endoftext|>\n",
      "<|startoftext|>204<|endoftext|>\n",
      "<|startoftext|>205<|endoftext|>\n",
      "<|startoftext|>206<|endoftext|>\n",
      "<|startoftext|>207<|endoftext|>\n",
      "<|startoftext|>208<|endoftext|>\n",
      "<|startoftext|>209<|endoftext|>\n",
      "<|startoftext|>210<|endoftext|\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path checkpoint/run1\n",
      "Loạt idol đọ dáng khét lẹt huỏng.\n",
      "ản.\n",
      "I believe that the Nốn was created by the mind of man.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "I believe that man is the Creator of all things.\n",
      "ản.\n",
      "ản.\n",
      "I believe that man is the center of all things.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt dao ưọ hưọ oễng thọ nớo.\n",
      "                The most famous of all the cults of the Taoist monks is the cult of the alma-gods.\n",
      "                The cult of the alma-gods is divided into two main groups:\n",
      "                The first group is the cult of the alma-gods and the second group is the cult of the alma-gods and the cult of the alma-gods.\n",
      "                These cults are the foundations of the cult of the alma-gods, not only because they are an important part of the cult of the alma-gods, but also because they are important parts of the cult of the alma-gods.\n",
      "                These cults are the foundations of the cult of the alma-gods and the cult of the alma-gods.\n",
      "                These cults are the foundations of the cult of the alma-gods and\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt. The first thing that I said was that I was going to make a show of my talent. When I saw that, I knew that I had to do something special for the show. But I didn't want to do it alone.\n",
      "Hindi: I don't want to do it alone.\n",
      "Sa`eed: You don't want to do it alone.\n",
      "Sa`eed: I want to do it with your hand.\n",
      "Hindi: Why do you think I want to do it alone?\n",
      "Sa`eed: Because I want to be good.\n",
      "Sa`eed: I want to be good.\n",
      "Sa`eed: You don't want to do it alone.\n",
      "Sa`eed: I want to do it alone.\n",
      "Sa`eed: I want to do it alone.\n",
      "Sa`eed: Well, I want to do it alone.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: I want to do it alone.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: I want to\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt.\n",
      "\"He should have been sent to Szechuan for the reason of his education and then he should have been sent to the city for the sake of his career.\"\n",
      "\"When I heard of that, I could not help but feel ashamed. I had been told, however, that a great number of people had been sent to Szechuan for the sake of their careers. However, I was afraid that some of them would be sent to Szechuan for the sake of their careers. Therefore, I began to think about my future. \n",
      "\"I had never heard of a lot of people who were sent to Szechuan for their careers, and I had never heard of someone who was sent to Szechuan for the sake of their career. I had never heard of any people who were sent to Szechuan for their careers. \n",
      "\"I had never heard of any of the people who were sent to Szechuan for their careers. I had never heard of anybody who was sent to Szechuan for their careers. I had never heard of anybody who was sent to Szechuan for their careers\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt. The next day the queen left the house, having left the place as soon as the evening was over, and now she was gone as soon as evening had passed. With these two provinces, it seemed the least of these two provinces, and the most of them.\n",
      "In the morning, the queen sent for the king, and went to the king's residence, where he sat before the king's chamber, where he made some preparations of things for the night, and then came to the king's chamber, where he sat before the king's chamber, and he made some preparations of things for the morning. There was no sign of the king, and no sign of the king's office, nor of his house, nor of his goods. The queen went up to the king's room, where he lay down his head, and took him aside, and said to him with a loud voice:\n",
      "\"I have made my preparations for the morning, and have made my preparations for the evening. I have made my preparations for the evening, and have made my preparations for the evening. Let me go and go, and I shall go\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=250,\n",
    "              temperature=0.7,\n",
    "              prefix=\"Loạt idol đọ dáng khét lẹt\",\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
