{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ulity\n",
    "https://colab.research.google.com/drive/1CP-hLllqq4lpi0jFxGg_T51zj0tlu0SY?usp=sharing#scrollTo=4drWBjGtZwij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/33862420/ipython-notebook-how-to-reload-all-modules-in-a-specific-python-file\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tham khảo tài liệu notebook cho việc hiểu tham số:\n",
    "https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#scrollTo=aeXshJM-Cuaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#setting parameters\n",
    "#the path to folder or files to train on\n",
    "\n",
    "# extract column data into csv file\n",
    "\n",
    "source = \"./data/crawl_data_202303041834.csv\"\n",
    "dataset = \"./data/crawl_data_202303041834_content.csv\"\n",
    "df = pd.read_csv(source)\n",
    "df['content'].to_csv('./data/crawl_data_202303041834_content.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path checkpoint/run1\n",
      "For larger models, the recommended finetune() parameters are:\n",
      "\tuse_memory_saving_gradients = True\n",
      "\tonly_train_transformer_layers = True\n",
      "\taccumulate_gradients = 1\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "input must have last dimension >= k = 40 but is 0 for '{{node cond/TopKV2}} = TopKV2[T=DT_FLOAT, sorted=true](cond/TopKV2/truediv, cond/TopKV2/k)' with input shapes: [1,0], [] and with computed input tensors: input[1] = <40>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m sess \u001b[39m=\u001b[39m gpt2\u001b[39m.\u001b[39mstart_tf_sess()\n\u001b[1;32m     34\u001b[0m \u001b[39m#finetuning\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m gpt2\u001b[39m.\u001b[39;49mfinetune(sess,\n\u001b[1;32m     36\u001b[0m                 dataset\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m     37\u001b[0m                 model_name\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m     38\u001b[0m                 steps\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m     39\u001b[0m                 restore_from\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfresh\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m                 run_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrun1\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     41\u001b[0m                 overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m     42\u001b[0m                 print_every\u001b[39m=\u001b[39;49mprint_every,\n\u001b[1;32m     43\u001b[0m                 sample_every\u001b[39m=\u001b[39;49msample_every,\n\u001b[1;32m     44\u001b[0m                 save_every\u001b[39m=\u001b[39;49msave_every, \n\u001b[1;32m     45\u001b[0m                 sample_length\u001b[39m=\u001b[39;49msample_length\n\u001b[1;32m     46\u001b[0m             )\n\u001b[1;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinetuning Complete\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/projects/pyml/text-generation/gpt_2_me/gpt_2_simple/gpt_2.py:204\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    199\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mmodel(hparams\u001b[39m=\u001b[39mhparams, X\u001b[39m=\u001b[39mcontext, gpus\u001b[39m=\u001b[39mgpus, reuse\u001b[39m=\u001b[39mreuse)\n\u001b[1;32m    200\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(\n\u001b[1;32m    201\u001b[0m     input_tensor\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m    202\u001b[0m         labels\u001b[39m=\u001b[39mcontext[:, \u001b[39m1\u001b[39m:], logits\u001b[39m=\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m][:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[0;32m--> 204\u001b[0m tf_sample \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39;49msample_sequence(\n\u001b[1;32m    205\u001b[0m     hparams\u001b[39m=\u001b[39;49mhparams,\n\u001b[1;32m    206\u001b[0m     length\u001b[39m=\u001b[39;49msample_length,\n\u001b[1;32m    207\u001b[0m     context\u001b[39m=\u001b[39;49mcontext,\n\u001b[1;32m    208\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    209\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m    210\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\n\u001b[1;32m    212\u001b[0m all_vars \u001b[39m=\u001b[39m [v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrainable_variables() \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m v\u001b[39m.\u001b[39mname]\n\u001b[1;32m    213\u001b[0m train_vars \u001b[39m=\u001b[39m [v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_vars \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m/h\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m v\u001b[39m.\u001b[39mname] \u001b[39mif\u001b[39;00m only_train_transformer_layers \u001b[39melse\u001b[39;00m all_vars\n",
      "File \u001b[0;32m~/Documents/projects/pyml/text-generation/gpt_2_me/gpt_2_simple/src/sample.py:89\u001b[0m, in \u001b[0;36msample_sequence\u001b[0;34m(hparams, length, start_token, batch_size, context, temperature, top_k, top_p)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcond\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     87\u001b[0m _, _, tokens \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m     88\u001b[0m     tf\u001b[39m.\u001b[39mstop_gradient,\n\u001b[0;32m---> 89\u001b[0m     tf\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m     90\u001b[0m         cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m     91\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m     92\u001b[0m         maximum_iterations\u001b[39m=\u001b[39;49mlength,\n\u001b[1;32m     93\u001b[0m         loop_vars\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     94\u001b[0m             context_output[\u001b[39m'\u001b[39;49m\u001b[39mpresents\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     95\u001b[0m             context[:, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     96\u001b[0m             context,\n\u001b[1;32m     97\u001b[0m         ],\n\u001b[1;32m     98\u001b[0m         shape_invariants\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     99\u001b[0m             tf\u001b[39m.\u001b[39;49mTensorShape(model\u001b[39m.\u001b[39;49mpast_shape(hparams\u001b[39m=\u001b[39;49mhparams, batch_size\u001b[39m=\u001b[39;49mbatch_size)),\n\u001b[1;32m    100\u001b[0m             tf\u001b[39m.\u001b[39;49mTensorShape([batch_size]),\n\u001b[1;32m    101\u001b[0m             tf\u001b[39m.\u001b[39;49mTensorShape([batch_size, \u001b[39mNone\u001b[39;49;00m]),\n\u001b[1;32m    102\u001b[0m         ],\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2516\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2341\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2342\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2357\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2358\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2359\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2360\u001b[0m \n\u001b[1;32m   2361\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2514\u001b[0m \n\u001b[1;32m   2515\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2516\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[1;32m   2517\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2518\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   2519\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[1;32m   2520\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2521\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2522\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m   2523\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m   2524\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2525\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2526\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2716\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2713\u001b[0m executing_eagerly \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   2714\u001b[0m \u001b[39mif\u001b[39;00m (util\u001b[39m.\u001b[39mEnableControlFlowV2(ops\u001b[39m.\u001b[39mget_default_graph()) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   2715\u001b[0m     \u001b[39mnot\u001b[39;00m executing_eagerly):\n\u001b[0;32m-> 2716\u001b[0m   \u001b[39mreturn\u001b[39;00m while_v2\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   2717\u001b[0m       cond,\n\u001b[1;32m   2718\u001b[0m       body,\n\u001b[1;32m   2719\u001b[0m       loop_vars,\n\u001b[1;32m   2720\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2721\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2722\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2723\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2724\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49mreturn_same_structure,\n\u001b[1;32m   2725\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop)\n\u001b[1;32m   2727\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mwhile\u001b[39m\u001b[39m\"\u001b[39m, loop_vars):\n\u001b[1;32m   2728\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loop_vars:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:222\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[39m# TODO(srbs): Update lowering code to create _Enter nodes with\u001b[39;00m\n\u001b[1;32m    219\u001b[0m   \u001b[39m# is_constant=True for inputs that are directly passed to outputs.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m [loop_counter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, maximum_iterations_arg] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(outputs)\n\u001b[0;32m--> 222\u001b[0m body_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    223\u001b[0m     body_name,\n\u001b[1;32m    224\u001b[0m     wrapped_body,\n\u001b[1;32m    225\u001b[0m     [],  \u001b[39m# We provide signature instead of args.\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m     {},\n\u001b[1;32m    227\u001b[0m     signature\u001b[39m=\u001b[39;49mfunc_graph_signature,\n\u001b[1;32m    228\u001b[0m     func_graph\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mWhileBodyFuncGraph(\n\u001b[1;32m    229\u001b[0m         body_name, collections\u001b[39m=\u001b[39;49mops\u001b[39m.\u001b[39;49mget_default_graph()\u001b[39m.\u001b[39;49m_collections),  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39;49madd_control_dependencies,\n\u001b[1;32m    231\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[1;32m    232\u001b[0m \u001b[39m# Add external captures of body to the list of loop vars.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m# Note that external tensors will be treated as loop invariants, i.e.,\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# the value of that tensor in each iteration is the same as it was at the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# beginning of the loop execution.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m deferred_external_captures \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(\n\u001b[1;32m    237\u001b[0m     [c() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m body_graph\u001b[39m.\u001b[39mdeferred_external_captures],\n\u001b[1;32m    238\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:200\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.wrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    193\u001b[0m   ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39mcapture(t)\n\u001b[1;32m    195\u001b[0m \u001b[39m# Convert the flow variables in `args` to TensorArrays. `args` should\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# already have the same structure as `orig_loop_vars` but currently there\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# is no nest.zip so we call `_pack_sequence_as` which flattens `args`,\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# converts flows in `args` to TensorArrays and packs it into the\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# structure of `loop_vars_signature`.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m outputs \u001b[39m=\u001b[39m body(\n\u001b[1;32m    201\u001b[0m     \u001b[39m*\u001b[39;49m_pack_sequence_as(loop_vars_signature, flat_orig_loop_vars, args))\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(outputs):\n\u001b[1;32m    203\u001b[0m   outputs \u001b[39m=\u001b[39m [outputs]\n",
      "File \u001b[0;32m~/Documents/projects/pyml/text-generation/gpt_2_me/gpt_2_simple/src/sample.py:75\u001b[0m, in \u001b[0;36msample_sequence.<locals>.body\u001b[0;34m(past, prev, output)\u001b[0m\n\u001b[1;32m     73\u001b[0m     logits \u001b[39m=\u001b[39m top_p_logits(logits, p\u001b[39m=\u001b[39mtop_p)\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     logits \u001b[39m=\u001b[39m top_k_logits(logits, k\u001b[39m=\u001b[39;49mtop_k)\n\u001b[1;32m     76\u001b[0m samples \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mcategorical(\n\u001b[1;32m     77\u001b[0m     logits, num_samples\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32)\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     79\u001b[0m     tf\u001b[39m.\u001b[39mconcat([past, next_outputs[\u001b[39m'\u001b[39m\u001b[39mpresents\u001b[39m\u001b[39m'\u001b[39m]], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m     80\u001b[0m     tf\u001b[39m.\u001b[39msqueeze(samples, axis\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m]),\n\u001b[1;32m     81\u001b[0m     tf\u001b[39m.\u001b[39mconcat([output, samples], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     82\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/projects/pyml/text-generation/gpt_2_me/gpt_2_simple/src/sample.py:19\u001b[0m, in \u001b[0;36mtop_k_logits\u001b[0;34m(logits, k)\u001b[0m\n\u001b[1;32m     13\u001b[0m     min_values \u001b[39m=\u001b[39m values[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tf\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m     15\u001b[0m         logits \u001b[39m<\u001b[39m min_values,\n\u001b[1;32m     16\u001b[0m         tf\u001b[39m.\u001b[39mones_like(logits, dtype\u001b[39m=\u001b[39mlogits\u001b[39m.\u001b[39mdtype) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1e10\u001b[39m,\n\u001b[1;32m     17\u001b[0m         logits,\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcond(\n\u001b[1;32m     20\u001b[0m     pred\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mequal(k, \u001b[39m0\u001b[39;49m),\n\u001b[1;32m     21\u001b[0m     true_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m: logits,\n\u001b[1;32m     22\u001b[0m     false_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m: _top_k(),\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/projects/pyml/text-generation/gpt_2_me/gpt_2_simple/src/sample.py:22\u001b[0m, in \u001b[0;36mtop_k_logits.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     min_values \u001b[39m=\u001b[39m values[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tf\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m     15\u001b[0m         logits \u001b[39m<\u001b[39m min_values,\n\u001b[1;32m     16\u001b[0m         tf\u001b[39m.\u001b[39mones_like(logits, dtype\u001b[39m=\u001b[39mlogits\u001b[39m.\u001b[39mdtype) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1e10\u001b[39m,\n\u001b[1;32m     17\u001b[0m         logits,\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(\n\u001b[1;32m     20\u001b[0m     pred\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mequal(k, \u001b[39m0\u001b[39m),\n\u001b[1;32m     21\u001b[0m     true_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m: logits,\n\u001b[0;32m---> 22\u001b[0m     false_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m: _top_k(),\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/pyml/text-generation/gpt_2_me/gpt_2_simple/src/sample.py:12\u001b[0m, in \u001b[0;36mtop_k_logits.<locals>._top_k\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_top_k\u001b[39m():\n\u001b[0;32m---> 12\u001b[0m     values, _ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mtop_k(logits, k\u001b[39m=\u001b[39;49mk)\n\u001b[1;32m     13\u001b[0m     min_values \u001b[39m=\u001b[39m values[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, tf\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m     15\u001b[0m         logits \u001b[39m<\u001b[39m min_values,\n\u001b[1;32m     16\u001b[0m         tf\u001b[39m.\u001b[39mones_like(logits, dtype\u001b[39m=\u001b[39mlogits\u001b[39m.\u001b[39mdtype) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1e10\u001b[39m,\n\u001b[1;32m     17\u001b[0m         logits,\n\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: input must have last dimension >= k = 40 but is 0 for '{{node cond/TopKV2}} = TopKV2[T=DT_FLOAT, sorted=true](cond/TopKV2/truediv, cond/TopKV2/k)' with input shapes: [1,0], [] and with computed input tensors: input[1] = <40>."
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "from gpt_2_me.gpt_2_simple.gpt_2 import *\n",
    "import gpt_2_me.gpt_2_simple.gpt_2 as gpt2\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "model_name = \"NlpHUST/gpt2-vietnamese\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n",
    "\n",
    "#how many steps it will perform\n",
    "steps = 120\n",
    "#determines whether to start from the base or a later checkpoint, more to follow about this\n",
    "restore_from = \"lastest\" \n",
    "#Set to `True` if you want to continue finetuning an existing model \n",
    "#(w/ `restore_from='latest'`) without creating duplicate copies. \n",
    "overwrite = True\n",
    "#how often to print results\n",
    "print_every = 5\n",
    "#how often to provide with generated samples\n",
    "sample_every = 100000\n",
    "#when providing sample, how many tokens to generate\n",
    "sample_length = 100\n",
    "#how often to save a check point\n",
    "save_every = 20\n",
    "\n",
    "#starting tensor flow session\n",
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "#finetuning\n",
    "gpt2.finetune(sess,\n",
    "                dataset=dataset,\n",
    "                model_name=model_name,\n",
    "                steps=steps,\n",
    "                restore_from='fresh',\n",
    "                run_name='run1',\n",
    "                overwrite=overwrite,\n",
    "                print_every=print_every,\n",
    "                sample_every=sample_every,\n",
    "                save_every=save_every, \n",
    "                sample_length=sample_length\n",
    "            )\n",
    "print(\"Finetuning Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path checkpoint/run1\n",
      "|<|startoftext|>147<|endoftext|>\n",
      "<|startoftext|>148<|endoftext|>\n",
      "<|startoftext|>149<|endoftext|>\n",
      "<|startoftext|>150<|endoftext|>\n",
      "<|startoftext|>151<|endoftext|>\n",
      "<|startoftext|>152<|endoftext|>\n",
      "<|startoftext|>153<|endoftext|>\n",
      "<|startoftext|>154<|endoftext|>\n",
      "<|startoftext|>155<|endoftext|>\n",
      "<|startoftext|>156<|endoftext|>\n",
      "<|startoftext|>157<|endoftext|>\n",
      "<|startoftext|>158<|endoftext|>\n",
      "<|startoftext|>159<|endoftext|>\n",
      "<|startoftext|>160<|endoftext|>\n",
      "<|startoftext|>161<|endoftext|>\n",
      "<|startoftext|>162<|endoftext|>\n",
      "<|startoftext|>163<|endoftext|>\n",
      "<|startoftext|>164<|endoftext|>\n",
      "<|startoftext|>165<|endoftext|>\n",
      "<|startoftext|>166<|endoftext|>\n",
      "<|startoftext|>167<|endoftext|>\n",
      "<|startoftext|>168<|endoftext|>\n",
      "<|startoftext|>169<|endoftext|>\n",
      "<|startoftext|>170<|endoftext|>\n",
      "<|startoftext|>171<|endoftext|>\n",
      "<|startoftext|>172<|endoftext|>\n",
      "<|startoftext|>173<|endoftext|>\n",
      "<|startoftext|>174<|endoftext|>\n",
      "<|startoftext|>175<|endoftext|>\n",
      "<|startoftext|>176<|endoftext|>\n",
      "<|startoftext|>177<|endoftext|>\n",
      "<|startoftext|>178<|endoftext|>\n",
      "<|startoftext|>179<|endoftext|>\n",
      "<|startoftext|>180<|endoftext|>\n",
      "<|startoftext|>181<|endoftext|>\n",
      "<|startoftext|>182<|endoftext|>\n",
      "<|startoftext|>183<|endoftext|>\n",
      "<|startoftext|>184<|endoftext|>\n",
      "<|startoftext|>185<|endoftext|>\n",
      "<|startoftext|>186<|endoftext|>\n",
      "<|startoftext|>187<|endoftext|>\n",
      "<|startoftext|>188<|endoftext|>\n",
      "<|startoftext|>189<|endoftext|>\n",
      "<|startoftext|>190<|endoftext|>\n",
      "<|startoftext|>191<|endoftext|>\n",
      "<|startoftext|>192<|endoftext|>\n",
      "<|startoftext|>193<|endoftext|>\n",
      "<|startoftext|>194<|endoftext|>\n",
      "<|startoftext|>195<|endoftext|>\n",
      "<|startoftext|>196<|endoftext|>\n",
      "<|startoftext|>197<|endoftext|>\n",
      "<|startoftext|>198<|endoftext|>\n",
      "<|startoftext|>199<|endoftext|>\n",
      "<|startoftext|>200<|endoftext|>\n",
      "<|startoftext|>201<|endoftext|>\n",
      "<|startoftext|>202<|endoftext|>\n",
      "<|startoftext|>203<|endoftext|>\n",
      "<|startoftext|>204<|endoftext|>\n",
      "<|startoftext|>205<|endoftext|>\n",
      "<|startoftext|>206<|endoftext|>\n",
      "<|startoftext|>207<|endoftext|>\n",
      "<|startoftext|>208<|endoftext|>\n",
      "<|startoftext|>209<|endoftext|>\n",
      "<|startoftext|>210<|endoftext|\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path checkpoint/run1\n",
      "Loạt idol đọ dáng khét lẹt huỏng.\n",
      "ản.\n",
      "I believe that the Nốn was created by the mind of man.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "I believe that man is the Creator of all things.\n",
      "ản.\n",
      "ản.\n",
      "I believe that man is the center of all things.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "ản.\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt dao ưọ hưọ oễng thọ nớo.\n",
      "                The most famous of all the cults of the Taoist monks is the cult of the alma-gods.\n",
      "                The cult of the alma-gods is divided into two main groups:\n",
      "                The first group is the cult of the alma-gods and the second group is the cult of the alma-gods and the cult of the alma-gods.\n",
      "                These cults are the foundations of the cult of the alma-gods, not only because they are an important part of the cult of the alma-gods, but also because they are important parts of the cult of the alma-gods.\n",
      "                These cults are the foundations of the cult of the alma-gods and the cult of the alma-gods.\n",
      "                These cults are the foundations of the cult of the alma-gods and\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt. The first thing that I said was that I was going to make a show of my talent. When I saw that, I knew that I had to do something special for the show. But I didn't want to do it alone.\n",
      "Hindi: I don't want to do it alone.\n",
      "Sa`eed: You don't want to do it alone.\n",
      "Sa`eed: I want to do it with your hand.\n",
      "Hindi: Why do you think I want to do it alone?\n",
      "Sa`eed: Because I want to be good.\n",
      "Sa`eed: I want to be good.\n",
      "Sa`eed: You don't want to do it alone.\n",
      "Sa`eed: I want to do it alone.\n",
      "Sa`eed: I want to do it alone.\n",
      "Sa`eed: Well, I want to do it alone.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: I want to do it alone.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: Maybe.\n",
      "Sa`eed: I want to\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt.\n",
      "\"He should have been sent to Szechuan for the reason of his education and then he should have been sent to the city for the sake of his career.\"\n",
      "\"When I heard of that, I could not help but feel ashamed. I had been told, however, that a great number of people had been sent to Szechuan for the sake of their careers. However, I was afraid that some of them would be sent to Szechuan for the sake of their careers. Therefore, I began to think about my future. \n",
      "\"I had never heard of a lot of people who were sent to Szechuan for their careers, and I had never heard of someone who was sent to Szechuan for the sake of their career. I had never heard of any people who were sent to Szechuan for their careers. \n",
      "\"I had never heard of any of the people who were sent to Szechuan for their careers. I had never heard of anybody who was sent to Szechuan for their careers. I had never heard of anybody who was sent to Szechuan for their careers\n",
      "====================\n",
      "Loạt idol đọ dáng khét lẹt. The next day the queen left the house, having left the place as soon as the evening was over, and now she was gone as soon as evening had passed. With these two provinces, it seemed the least of these two provinces, and the most of them.\n",
      "In the morning, the queen sent for the king, and went to the king's residence, where he sat before the king's chamber, where he made some preparations of things for the night, and then came to the king's chamber, where he sat before the king's chamber, and he made some preparations of things for the morning. There was no sign of the king, and no sign of the king's office, nor of his house, nor of his goods. The queen went up to the king's room, where he lay down his head, and took him aside, and said to him with a loud voice:\n",
      "\"I have made my preparations for the morning, and have made my preparations for the evening. I have made my preparations for the evening, and have made my preparations for the evening. Let me go and go, and I shall go\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=250,\n",
    "              temperature=0.7,\n",
    "              prefix=\"Loạt idol đọ dáng khét lẹt\",\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
